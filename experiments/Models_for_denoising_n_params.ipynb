{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import backend as K\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from fastmri_recon.models.functional_models.unet import unet\n",
    "from fastmri_recon.models.subclassed_models.denoisers.dncnn import DnCNN\n",
    "from fastmri_recon.models.subclassed_models.denoisers.focnet import FocNet, DEFAULT_COMMUNICATION_BETWEEN_SCALES\n",
    "from fastmri_recon.models.subclassed_models.denoisers.focnet import DEFAULT_N_CONVS_PER_SCALE as default_n_convs_focnet\n",
    "from fastmri_recon.models.subclassed_models.denoisers.mwcnn import MWCNN, DEFAULT_N_FILTERS_PER_SCALE\n",
    "from fastmri_recon.models.subclassed_models.denoisers.mwcnn import DEFAULT_N_CONVS_PER_SCALE as default_n_convs_mwcnn\n",
    "from fastmri_recon.models.subclassed_models.xpdnet import XPDNet\n",
    "from fastmri_recon.models.training.compile import default_model_compile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_primal = 5\n",
    "test_memory_fit = False\n",
    "write_to_csv = True\n",
    "\n",
    "if write_to_csv:\n",
    "    df_params = pd.DataFrame(columns=['model_name', 'model_size', 'n_params'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_works_in_xpdnet_train(model, n_scales, res):\n",
    "    run_params = {\n",
    "        'n_primal': n_primal,\n",
    "        'multicoil': False,\n",
    "        'n_scales': n_scales,\n",
    "        'n_iter': 10,\n",
    "        'refine_smaps': False,\n",
    "        'res': res,\n",
    "    }\n",
    "    model = XPDNet(model, **run_params)\n",
    "    default_model_compile(model, lr=1e-3, loss='mae')\n",
    "    model.fit(\n",
    "        x=[\n",
    "            tf.zeros([1, 640, 640, 1], dtype=tf.complex64),\n",
    "            tf.zeros([1, 640, 640], dtype=tf.complex64),\n",
    "        ],\n",
    "        y=tf.zeros([1, 320, 320, 1]),\n",
    "        epochs=1,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f97bdcda23994490b7bcaba43d98ca3f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Dncnn', max=1.0, style=ProgressStyle(description_width='i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DnCNN small\n",
      "10154\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#dncnn\n",
    "params = {}\n",
    "params['big'] = dict(\n",
    "    n_convs=20,\n",
    "    n_filters=64,\n",
    ")\n",
    "params['medium'] = dict(\n",
    "    n_convs=10,\n",
    "    n_filters=32,\n",
    ")\n",
    "params['small'] = dict(\n",
    "    n_convs=5,\n",
    "    n_filters=16,\n",
    ")\n",
    "\n",
    "for param_name, param_values in tqdm(params.items(), 'Dncnn'):\n",
    "    print('DnCNN', param_name)\n",
    "    model = DnCNN(n_outputs=2*n_primal, res=False, **param_values)\n",
    "    model(tf.zeros([1, 32, 32, 2*(n_primal + 1)]))\n",
    "    trainable_count = np.sum([K.count_params(w) for w in model.trainable_weights])\n",
    "    print(trainable_count)\n",
    "    if test_memory_fit:\n",
    "        try:\n",
    "            test_works_in_xpdnet_train(model, n_scales=0, res=True)\n",
    "        except:\n",
    "            print('Does not fit in memory for xpdnet')\n",
    "    if write_to_csv:\n",
    "        df_params = df_params.append(dict(\n",
    "            model_name='DnCNN',\n",
    "            model_size=param_name,\n",
    "            n_params=trainable_count,\n",
    "        ), ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d93932f671d546a08d59d5e986846b81",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='unet', max=1.0, style=ProgressStyle(description_width='in…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "U-net small\n",
      "58536\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#unet\n",
    "params = {}\n",
    "# params['big'] = dict(\n",
    "#     n_layers=4,\n",
    "#     layers_n_channels=[32, 64, 128, 256],\n",
    "#     layers_n_non_lins=2,\n",
    "# )\n",
    "# params['medium'] = dict(\n",
    "#     n_layers=4,\n",
    "#     layers_n_channels=[16, 32, 64, 128],\n",
    "#     layers_n_non_lins=2,\n",
    "# )\n",
    "params['small'] = dict(\n",
    "    n_layers=3,\n",
    "    layers_n_channels=[16, 32, 64],\n",
    "    layers_n_non_lins=1,\n",
    ")\n",
    "for param_name, param_values in tqdm(params.items(), 'unet'):\n",
    "    print('U-net', param_name)\n",
    "    model = unet(\n",
    "        input_size=(None, None, 2*(n_primal + 1)), \n",
    "        compile=False, \n",
    "        res=False, \n",
    "        n_output_channels=2*n_primal,\n",
    "        **param_values,\n",
    "    )\n",
    "    model(tf.zeros([1, 32, 32, 2*(n_primal + 1)]))\n",
    "    trainable_count = np.sum([K.count_params(w) for w in model.trainable_weights])\n",
    "    print(trainable_count)\n",
    "    if test_memory_fit:\n",
    "        try:\n",
    "            test_works_in_xpdnet_train(model, n_scales=param_values['n_layers'], res=True)\n",
    "        except:\n",
    "            print('Does not fit in memory for xpdnet')\n",
    "    if write_to_csv:\n",
    "        df_params = df_params.append(dict(\n",
    "            model_name='U-net',\n",
    "            model_size=param_name,\n",
    "            n_params=trainable_count,\n",
    "        ), ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "99727e6d90d349e7a15f738bfcaca856",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='mwcnn', max=1.0, style=ProgressStyle(description_width='i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MWCNN small\n",
      "338122\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#mwcnn\n",
    "params = {}\n",
    "# params['big'] = dict(\n",
    "#     n_scales=3,\n",
    "#     n_filters_per_scale=DEFAULT_N_FILTERS_PER_SCALE,\n",
    "#     n_convs_per_scale=default_n_convs_mwcnn,\n",
    "#     n_first_convs=3,\n",
    "#     first_conv_n_filters=64,\n",
    "# )\n",
    "# params['medium'] = dict(\n",
    "#     n_scales=3,\n",
    "#     n_filters_per_scale=[64, 128, 256],\n",
    "#     n_convs_per_scale=default_n_convs_mwcnn,\n",
    "#     n_first_convs=2,\n",
    "#     first_conv_n_filters=32,\n",
    "# )\n",
    "params['small'] = dict(\n",
    "    n_scales=2,\n",
    "    n_filters_per_scale=[32, 64],\n",
    "    n_convs_per_scale=[2, 2],\n",
    "    n_first_convs=2,\n",
    "    first_conv_n_filters=32,\n",
    ")\n",
    "for param_name, param_values in tqdm(params.items(), 'mwcnn'):\n",
    "    print('MWCNN', param_name)\n",
    "    model = MWCNN(res=False, n_outputs=2*n_primal, **param_values)\n",
    "    model(tf.zeros([1, 32, 32, 2*(n_primal + 1)]))\n",
    "    trainable_count = np.sum([K.count_params(w) for w in model.trainable_weights])\n",
    "    print(trainable_count)\n",
    "    if test_memory_fit:\n",
    "        try:\n",
    "            test_works_in_xpdnet_train(model, n_scales=param_values['n_scales'], res=True)\n",
    "        except:\n",
    "            print('Does not fit in memory for xpdnet')\n",
    "    if write_to_csv:\n",
    "        df_params = df_params.append(dict(\n",
    "            model_name='MWCNN',\n",
    "            model_size=param_name,\n",
    "            n_params=trainable_count,\n",
    "        ), ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd1a4b7361fe4e4b9d4caba709bddb74",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='focnet', max=1.0, style=ProgressStyle(description_width='…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FocNet small\n",
      "457402.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#focnet\n",
    "params = {}\n",
    "# params['big'] = dict(\n",
    "#     n_scales=4,\n",
    "#     n_filters=128,\n",
    "#     n_convs_per_scale=default_n_convs_focnet,\n",
    "#     communications_between_scales=DEFAULT_COMMUNICATION_BETWEEN_SCALES,\n",
    "# )\n",
    "# params['medium'] = dict(\n",
    "#     n_scales=4,\n",
    "#     n_filters=64,\n",
    "#     n_convs_per_scale=default_n_convs_focnet,\n",
    "#     communications_between_scales=DEFAULT_COMMUNICATION_BETWEEN_SCALES,\n",
    "# )\n",
    "params['small'] = dict(\n",
    "    n_scales=3,\n",
    "    n_filters=32,\n",
    "    n_convs_per_scale=default_n_convs_focnet[:-1],\n",
    "    communications_between_scales=DEFAULT_COMMUNICATION_BETWEEN_SCALES[:-1],\n",
    ")\n",
    "for param_name, param_values in tqdm(params.items(), 'focnet'):\n",
    "    print('FocNet', param_name)\n",
    "    model = FocNet(n_outputs=2*n_primal, **param_values)\n",
    "    model(tf.zeros([1, 32, 32, 2*(n_primal + 1)]))\n",
    "    trainable_count = np.sum([K.count_params(w) for w in model.trainable_weights])\n",
    "    print(trainable_count)\n",
    "    if test_memory_fit:\n",
    "        try:\n",
    "            test_works_in_xpdnet_train(model, n_scales=param_values['n_scales'], res=False)\n",
    "        except:\n",
    "            print('Does not fit in memory for xpdnet')\n",
    "    if write_to_csv:\n",
    "        df_params = df_params.append(dict(\n",
    "            model_name='FocNet',\n",
    "            model_size=param_name,\n",
    "            n_params=trainable_count,\n",
    "        ), ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_name</th>\n",
       "      <th>model_size</th>\n",
       "      <th>n_params</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DnCNN</td>\n",
       "      <td>small</td>\n",
       "      <td>10154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>U-net</td>\n",
       "      <td>small</td>\n",
       "      <td>58536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MWCNN</td>\n",
       "      <td>small</td>\n",
       "      <td>338122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>FocNet</td>\n",
       "      <td>small</td>\n",
       "      <td>457402</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  model_name model_size n_params\n",
       "0      DnCNN      small    10154\n",
       "1      U-net      small    58536\n",
       "2      MWCNN      small   338122\n",
       "3     FocNet      small   457402"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_params"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
